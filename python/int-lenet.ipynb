{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/thomasboser/anaconda/envs/python3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "import operator\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Lambda\n",
    "from keras.activations import relu\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load mnist dataset and shape it to be supported by Keras\n",
    "Taken from Keras example on github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "#set up data for training\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our training model\n",
    "We train our model with a sigmoid activation and floating point weights.  \n",
    "The model trains fast and gets good accuracy (better than that reported in Yann LeCun's paper!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 24, 24, 6)         156       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 24, 24, 6)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 12, 12, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 8, 8, 16)          2416      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 120)               30840     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 84)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 44,426\n",
      "Trainable params: 44,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 27s 456us/step - loss: 1.1502 - acc: 0.6515 - val_loss: 0.2836 - val_acc: 0.9269\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 26s 425us/step - loss: 0.1983 - acc: 0.9497 - val_loss: 0.1434 - val_acc: 0.9612\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 27s 452us/step - loss: 0.1156 - acc: 0.9681 - val_loss: 0.1180 - val_acc: 0.9661\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.0814 - acc: 0.9767 - val_loss: 0.1035 - val_acc: 0.9713\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 30s 505us/step - loss: 0.0632 - acc: 0.9813 - val_loss: 0.0938 - val_acc: 0.9735\n",
      "Test loss: 0.0937819454857\n",
      "Test accuracy: 0.9735\n"
     ]
    }
   ],
   "source": [
    "#model for training with sigmoid activation\n",
    "model = Sequential()\n",
    "model.add(Conv2D(6, kernel_size=(5, 5),\n",
    "                 input_shape=input_shape))\n",
    "model.add(Activation(relu))#, max_value=1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(16, (5, 5)))\n",
    "model.add(Activation(relu))#, max_value=1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120))\n",
    "model.add(Activation(relu))#, max_value=1)))\n",
    "model.add(Dense(84))\n",
    "model.add(Activation(relu))#, max_value=1)))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#show summary of our model\n",
    "model.summary()\n",
    "\n",
    "#train and test our model\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15961 -0.182806 0.00300721 -0.036846\n",
      "0.154745 -0.167102 0.0134561 -0.0279432\n",
      "0.182576 -0.180867 0.0173579 -0.0208082\n",
      "0.229306 -0.202454 0.0185709 -0.0194909\n",
      "0.247613 -0.281095 -0.00152354 -0.0298678\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    try:\n",
    "        print(np.amax(layer.get_weights()[0]), np.amin(layer.get_weights()[0]),\n",
    "              np.amax(layer.get_weights()[1]), np.amin(layer.get_weights()[1]))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same model, discrete weights, without the sigmoid activation\n",
    "This model will make the same predicitions without the sigmoid activation, and with discrete weights. We ensure we don't cause overflow on the FPGA by dividing by 512 after convolution and dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val = K.variable(256, name=\"val\")\n",
    "def lfunc(x):\n",
    "    return K.round(x/val)\n",
    "\n",
    "model_discrete = Sequential()\n",
    "model_discrete.add(Conv2D(6, kernel_size=(5, 5),\n",
    "                 input_shape=input_shape, activation='relu', use_bias=False))\n",
    "model_discrete.add(Lambda(lfunc))\n",
    "#model_discrete.add(Activation(lambda x: relu(x, max_value=65200)))\n",
    "model_discrete.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_discrete.add(Conv2D(16, (5, 5), activation='relu', use_bias=False))\n",
    "model_discrete.add(Lambda(lfunc))\n",
    "#model_discrete.add(Activation(lambda x: relu(x, max_value=65200)))\n",
    "model_discrete.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_discrete.add(Flatten())\n",
    "model_discrete.add(Dense(120, activation='relu'))\n",
    "model_discrete.add(Lambda(lfunc))\n",
    "#model_discrete.add(Activation(lambda x: relu(x, max_value=65200)))\n",
    "model_discrete.add(Dense(84, activation='relu'))\n",
    "model_discrete.add(Lambda(lfunc))\n",
    "#model_discrete.add(Activation(lambda x: relu(x, max_value=65200)))\n",
    "model_discrete.add(Dense(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#manually evaluate our model on a test set\n",
    "def evaluate_model(model, test_x, test_y):\n",
    "    num_correct = 0\n",
    "    for inp, outp in zip(test_x, test_y):\n",
    "        pred = model.predict(np.reshape(inp, (1, 28, 28, 1)))\n",
    "        max_index, max_value = max(enumerate(pred[0]), key=operator.itemgetter(1))\n",
    "        if int(outp[max_index]) == 1:\n",
    "            num_correct += 1\n",
    "    return num_correct #return # correctly predicted\n",
    "\n",
    "#magic function that applies an operation to every element in a numpy ndarray\n",
    "def mod_ndarray(array, operation):\n",
    "    if array.ndim == 1:\n",
    "        return [operation(x) for x in array]\n",
    "    else:\n",
    "        return [mod_ndarray(x, operation) for x in array]\n",
    "\n",
    "#turns a value from 0 to 1 into uint(8)\n",
    "def mult_255(val):\n",
    "    return round(val*255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9726 predicted correctly\n",
      "97.26 % predicted correctly\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(model.layers)):        \n",
    "    try:\n",
    "        model_discrete.layers[i].set_weights([np.asarray(mod_ndarray(model.layers[i].get_weights()[0], mult_255)), np.asarray(mod_ndarray(model.layers[i].get_weights()[1], mult_255))])\n",
    "    except:\n",
    "        try:\n",
    "            model_discrete.layers[i].set_weights([np.asarray(mod_ndarray(model.layers[i].get_weights()[0], mult_255))])\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "num_correct = evaluate_model(model_discrete, x_test, y_test)\n",
    "print(num_correct, \"predicted correctly\")\n",
    "print(num_correct/100, \"% predicted correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ok looks good. Let's save these weights and inputs.\n",
    "Float weights for OpenCL, discrete weights for the FPGA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fh = open(\"inputs.txt\", \"w\")\n",
    "for inp in x_test.flatten():\n",
    "    fh.write(str(inp)+\"\\n\")\n",
    "fh.close()\n",
    "\n",
    "fh = open(\"flat_weights_float.txt\", \"w\")\n",
    "for layer in model.layers:\n",
    "    wgt = layer.get_weights()\n",
    "    if wgt:\n",
    "        weights = wgt[0]\n",
    "        bias = wgt[1]\n",
    "        fh.write(layer.get_config()['name']+\"\\n\")\n",
    "        for s in weights.T.shape:\n",
    "            fh.write(str(s) + \" \")\n",
    "        fh.write(\"\\n\")\n",
    "        for weight in weights.T.flatten():\n",
    "            fh.write(str(weight)+\" \")\n",
    "        fh.write(\"\\n\")\n",
    "        for s in bias.shape:\n",
    "            fh.write(str(s) + \" \")\n",
    "        fh.write(\"\\n\")\n",
    "        for term in bias.flatten():\n",
    "            fh.write(str(term)+\" \")\n",
    "        fh.write(\"\\n\\n\")\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = open(\"flat_weights_discrete.txt\", \"w\")\n",
    "for i in range(0, len(model_discrete.layers)):\n",
    "    layer = model_discrete.layers[i]\n",
    "    wgt = layer.get_weights()\n",
    "    if wgt:\n",
    "        weights = wgt[0]\n",
    "        fh.write(layer.get_config()['name']+\"\\n\")\n",
    "        for s in weights.shape:\n",
    "            fh.write(str(s) + \" \")\n",
    "        fh.write(\"\\n\")\n",
    "        if 'conv' in layer.get_config()['name']:\n",
    "            for weight in weights.T.flatten():\n",
    "                fh.write(str(weight)+\" \")\n",
    "        else:\n",
    "            for weight in weights.T.flatten():\n",
    "                fh.write(str(weight)+\" \")\n",
    "        fh.write(\"\\n\")\n",
    "        if 'conv' in layer.get_config()['name']:\n",
    "            bias = model.layers[i].get_weights()[1]\n",
    "            for s in bias.shape:\n",
    "                fh.write(str(s) + \" \")\n",
    "            fh.write(\"\\n\")\n",
    "            for s in bias.flatten():\n",
    "                fh.write(str(0) + \" \")\n",
    "        else:\n",
    "            bias = wgt[1]\n",
    "            for s in bias.shape:\n",
    "                fh.write(str(s) + \" \")\n",
    "            fh.write(\"\\n\")\n",
    "            for term in bias.flatten():\n",
    "                fh.write(str(term)+\" \")\n",
    "        fh.write(\"\\n\\n\")\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-11.   9.   3. ..., -28. -36.  -7.]\n",
      " [ -9.   9.  24. ...,  31.  25. -12.]\n",
      " [ 20.   8. -25. ..., -13.  13.  20.]\n",
      " ..., \n",
      " [ 24.  -1.  15. ..., -22. -21.   7.]\n",
      " [-19.  -5.  36. ..., -19.   6.   6.]\n",
      " [-28.  -4.  -0. ..., -28.  -8.  10.]]\n"
     ]
    }
   ],
   "source": [
    "print(model_discrete.layers[7].get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "print(len(model_discrete.layers[7].get_weights()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.19486356e-08   1.39446669e-07   4.76224962e-08 ...,   9.99417067e-01\n",
      "    1.13776544e-08   2.33410677e-08]\n",
      " [  3.31773359e-11   7.70668612e-06   5.19435763e-01 ...,   2.20586160e-16\n",
      "    1.01457542e-09   1.76390261e-13]\n",
      " [  1.51103279e-06   8.23440731e-01   2.09005589e-06 ...,   5.47471864e-05\n",
      "    2.64673028e-04   1.09076118e-05]\n",
      " ..., \n",
      " [  5.85141812e-14   1.29158799e-08   6.53425014e-12 ...,   1.14739555e-06\n",
      "    2.78659996e-07   7.70947190e-06]\n",
      " [  4.48449899e-09   1.20941779e-09   1.61213098e-10 ...,   4.26159289e-07\n",
      "    1.98695078e-01   8.69585051e-07]\n",
      " [  3.79240639e-10   1.95763697e-14   3.98833722e-09 ...,   7.04337847e-14\n",
      "    9.61708158e-10   1.07173706e-11]]\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keras_get_layer_output(model, layer, test_input):\n",
    "    \"\"\"\n",
    "    Helper method, gives the output matrix from a Keras layer\n",
    "    \"\"\"\n",
    "    get_layer_output = K.function([model.layers[0].input],\n",
    "                                  [layer.output])\n",
    "    return get_layer_output([test_input])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxmin = []\n",
    "for tst in x_test[0:50]:\n",
    "    testin = np.reshape(tst, (1, 28, 28, 1))\n",
    "    for layer in model_discrete.layers:\n",
    "        out = keras_get_layer_output(model_discrete, layer, testin)\n",
    "        maxmin.append(np.amax(out))\n",
    "        maxmin.append(np.amin(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43459.0 -11748.0\n"
     ]
    }
   ],
   "source": [
    "print(max(maxmin), min(maxmin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
